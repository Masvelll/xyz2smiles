{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c67f2266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import torch\n",
    "sys.path.insert(1, 'MolT5/baselines')\n",
    "\n",
    "import numpy as np\n",
    "import dataloader\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e99934ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLOWED_ATOM_TYPES = ['C', 'O', 'N', 'F', 'S', 'Cl', 'Br', 'I', 'P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e7ba2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23998d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1211566/1359271894.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  geom = torch.load('./datasets/geom_train.pt')\n"
     ]
    }
   ],
   "source": [
    "geom = torch.load('./datasets/geom_train.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "660964bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "geom_cut = geom[:10000]\n",
    "torch.save(geom_cut, './datasets/geom_cut.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3481d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1211566/2042971286.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  geom_cut = torch.load('./datasets/geom_cut.pt')\n"
     ]
    }
   ],
   "source": [
    "geom_cut = torch.load('./datasets/geom_cut.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df20d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol = geom_cut[0]\n",
    "[ALLOWED_ATOM_TYPES[x] for x in mol['one_hot'].argmax(dim=-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6879c5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 436471/436471 [01:57<00:00, 3708.03it/s]\n"
     ]
    }
   ],
   "source": [
    "names = []\n",
    "positions = []\n",
    "atoms = []\n",
    "\n",
    "for mol in tqdm(geom):\n",
    "    names.append(mol['name'])\n",
    "    positions.append(mol['positions'])\n",
    "    atoms.append([ALLOWED_ATOM_TYPES[x] for x in mol['one_hot'].argmax(dim=-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8a2d3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 436471/436471 [08:52<00:00, 819.21it/s]\n"
     ]
    }
   ],
   "source": [
    "strings_data = []\n",
    "\n",
    "for mol in tqdm(geom):\n",
    "    string = ''\n",
    "    for pos, atom in zip(mol['positions'], [ALLOWED_ATOM_TYPES[x] for x in mol['one_hot'].argmax(dim=-1)]):\n",
    "        x,y,z = pos\n",
    "        string += f\"{atom} {x:.3f} {y:.3f} {z:.3f} \"\n",
    "    strings_data.append(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'geom' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mol \u001b[38;5;129;01min\u001b[39;00m \u001b[43mgeom\u001b[49m:\n\u001b[1;32m      2\u001b[0m     mol[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbonds\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'geom' is not defined"
     ]
    }
   ],
   "source": [
    "for mol in geom:\n",
    "    mol['bonds']\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28642a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1227971/2975242406.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embs = torch.load('/home/user12/burov/unimol_embeddings_project/geom_train_embeddings.pt')\n"
     ]
    }
   ],
   "source": [
    "embs = torch.load('/home/user12/burov/unimol_embeddings_project/geom_train_embeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0fe1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_emb = torch.rand(10000, 10000, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f44765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 436471)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0dada244",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_testval, y_train, y_testval = train_test_split(strings_data, names, random_state=42, train_size=0.9)\n",
    "X_val, X_test, y_val, y_test = train_test_split(strings_data, names, random_state=42, train_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3c2a063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327353"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "821739df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "392823it [00:00, 414834.33it/s]\n"
     ]
    }
   ],
   "source": [
    "last = 0\n",
    "with open('./MolT5/my_dataset/train.txt', 'w') as f:\n",
    "    for i, (s, name) in tqdm(enumerate(zip(X_train, y_train))):\n",
    "        f.write(f'CID{i:05}'+'\\t'+name+' \\t'+s+'\\n')\n",
    "        last = i\n",
    "with open('./MolT5/my_dataset/test.txt', 'w') as f:\n",
    "    for i, (s, name) in enumerate(zip(strings_data, names)):\n",
    "        f.write(f'CID{i+last:05}'+'\\t'+name+' \\t'+s+'\\n')\n",
    "        last = i\n",
    "with open('./MolT5/my_dataset/val.txt', 'w') as f:\n",
    "    for i, (s, name) in enumerate(zip(strings_data, names)):\n",
    "        f.write(f'CID{i+last:05}'+'\\t'+name+' \\t'+s+'\\n')\n",
    "\n",
    "    \n",
    "with open('./dataforcid.txt', 'w') as f:\n",
    "    for i, (s, name) in enumerate(zip(strings_data, names)):\n",
    "        f.write(f'CID{i:05}'+'\\t'+name+' \\t'+s+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e6ae00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, csv\n",
    "\n",
    "id2smi = {}\n",
    "with open('./dataforcid.txt') as f:\n",
    "    rdr = csv.DictReader(f, delimiter='\\t', fieldnames=['cid','mol2vec','desc'])\n",
    "    for row, smiles in zip(rdr, names):\n",
    "        cid = row['cid']\n",
    "        id2smi[cid] = smiles\n",
    "\n",
    "with open('./MolT5/evaluation/cid_to_smiles.pkl', 'wb') as f:\n",
    "    pickle.dump(id2smi, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "702d5e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoTokenizer, slow:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>\n",
      "\n",
      "T5Tokenizer, slow:\n",
      "<class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, T5Tokenizer\n",
    "\n",
    "print(\"AutoTokenizer, slow:\")\n",
    "tok = T5Tokenizer.from_pretrained(\"google/t5-v1_1-base\")\n",
    "print(type(tok))\n",
    "\n",
    "print(\"\\nT5Tokenizer, slow:\")\n",
    "tok2 = T5Tokenizer.from_pretrained(\"google/t5-v1_1-base\", use_fast=False)\n",
    "print(type(tok2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfd7e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, './MolT5/baselines')\n",
    "from main_transformer_caption2smiles import SmilesTokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eec1dcfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0, 1, 2, 0, 2, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 5],\n",
       "        device='cuda:0'),\n",
       " 19)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geom[0]['one_hot'].argmax(-1), geom[0]['positions'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8041d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3927af54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [03:43<00:00, 44.76it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch, json\n",
    "\n",
    "max_dist = 2.0\n",
    "out = open(\"bond_prompts_small.jsonl\", \"w\")\n",
    "\n",
    "for mol in tqdm(geom[:10000]):                           # geom — это list(dict)\n",
    "    xyz   = mol[\"positions\"]        # (N, 3)\n",
    "    types = mol[\"one_hot\"].argmax(-1)           # (N,)\n",
    "\n",
    "    # 1. полная матрица расстояний\n",
    "    dmat = torch.cdist(xyz, xyz, p=2)           # (N, N)\n",
    "\n",
    "    # 2. выбираем пары ≤ 2 Å (и не i==j)\n",
    "    idx   = (dmat > 0) & (dmat <= max_dist)\n",
    "    pairs = idx.nonzero(as_tuple=False)         # (M, 2)\n",
    "\n",
    "    if len(pairs) == 0:\n",
    "        continue\n",
    "\n",
    "    # ────────────────── постройте dict → (i,j) → one-hot в bond_orders ──────────\n",
    "    edge2order = {}\n",
    "    ei, bo = mol[\"edge_index\"], mol[\"bond_orders\"]          # (E,2), (E,10)\n",
    "    for k in range(ei.shape[0]):\n",
    "        u, v = map(int, ei[k])\n",
    "        edge2order[(u, v)] = bo[k]\n",
    "    # undirected: сразу добавим обратное направление\n",
    "        edge2order[(v, u)] = bo[k]\n",
    "\n",
    "    # ────────────────── определяем label для каждой пары ≤ 2 Å ───────────────────\n",
    "    labels = []\n",
    "    for i, j in pairs:                                      # pairs — Tensor (M,2)\n",
    "        vec = edge2order.get((int(i), int(j)))              # None, если нет связи\n",
    "        if vec is None:\n",
    "            bond = 0                                        # «no-bond»\n",
    "        else:\n",
    "            idx = vec.nonzero(as_tuple=True)[0].item()      # 0…9\n",
    "            bond = {0:0, 1:1, 2:2, 3:3, 4:1}.get(idx, 0)    # сводим к 0-3\n",
    "        labels.append(bond)\n",
    "\n",
    "\n",
    "    # 4. строим prompt\n",
    "    atom_map = \", \".join(f\"{i}:{'CONHXBOSPFI'[types[i]]}\"   # грубое сокращение; лучше RDKit\n",
    "                         for i in range(len(types)))\n",
    "    dist_map = \"\\n\".join(f\"[{int(i)},{int(j)}]={dmat[i,j]:.3f}\"\n",
    "                         for i, j in pairs)\n",
    "    system = (\"You are a chemist. Task: classify bond type (0 no-bond, 1 single, \"\n",
    "              \"2 double, 3 triple). Return ONLY JSON list \"\n",
    "              \"`[{\\\"pair\\\":[i,j],\\\"label\\\":n}, ...]` in the given order.\")\n",
    "    user   = f\"Atoms (index→element): {atom_map}\\nDistances (Å):\\n{dist_map}\"\n",
    "    assistant = json.dumps(\n",
    "        [{\"pair\":[int(i), int(j)], \"label\": int(l)}\n",
    "         for (i, j), l in zip(pairs, labels)],\n",
    "        separators=(\",\", \":\"))\n",
    "\n",
    "    json.dump({\"messages\":[\n",
    "        {\"role\":\"system\", \"content\":system},\n",
    "        {\"role\":\"user\",    \"content\":user},\n",
    "        {\"role\":\"assistant\",\"content\":assistant}\n",
    "    ]}, out); out.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8417cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xyz_smiles",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
